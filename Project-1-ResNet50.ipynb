{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid \n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import lightning as L\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.classification import BinaryF1Score, BinaryConfusionMatrix, BinaryAccuracy, BinaryRecall, BinaryPrecision\n",
    "from torchmetrics import MetricCollection\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "import PIL.Image\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SHUFFLE = False # Warning message that it should be turned off for train/val loaders check later\n",
    "NUM_WORERS = 7 # 7 because that what it suggested in a warning message\n",
    "PERSISTENT_WORKERS = True # Suggested to do this in a warning message for fatser init\n",
    "\n",
    "CUSTOM_TRAIN_VAL_SPLIT = True\n",
    "TRAIN_FRACTION = 0.8\n",
    "VALIDATION_FRACTION = 1 - TRAIN_FRACTION\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_LABELS = [\"Normal\", \"Pneumonia\"]\n",
    "DATA_DIR = \"chest_xray\" # Change this to chest_xray folder\n",
    "data_dir_train = DATA_DIR + \"/train\"\n",
    "data_dir_val = DATA_DIR + \"/val\"\n",
    "data_dir_test = DATA_DIR + \"/test\"\n",
    "\n",
    "# Some desired transforms for ResNet50\n",
    "# https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet50.html#torchvision.models.resnet50\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size = (256, 256)),\n",
    "        transforms.CenterCrop(size=(224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) # \n",
    "    ]\n",
    ")\n",
    "dataset_train = datasets.ImageFolder(data_dir_train, transform)\n",
    "dataset_val = datasets.ImageFolder(data_dir_val, transform)\n",
    "\n",
    "if CUSTOM_TRAIN_VAL_SPLIT:\n",
    "    dataset = torch.utils.data.ConcatDataset([dataset_train, dataset_val])\n",
    "    dataset_train, dataset_val = torch.utils.data.random_split(dataset, [TRAIN_FRACTION, VALIDATION_FRACTION])\n",
    "\n",
    "dataset_test = datasets.ImageFolder(data_dir_test, transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset_train, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=SHUFFLE, \n",
    "    num_workers=NUM_WORERS, \n",
    "    persistent_workers= PERSISTENT_WORKERS\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset_val, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=SHUFFLE, \n",
    "    num_workers=NUM_WORERS, \n",
    "    persistent_workers= PERSISTENT_WORKERS\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset_test, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=SHUFFLE, \n",
    "    num_workers=NUM_WORERS, \n",
    "    persistent_workers= PERSISTENT_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = next(iter(train_loader))\n",
    "images, labels = examples\n",
    "grid = make_grid(images[:9], nrow=3)\n",
    "plt.imshow(grid.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ResNet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load best resNet50 weights\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "#Change output layer to 2 classes\n",
    "model.fc = torch.nn.Linear(\n",
    "    in_features=2048,\n",
    "    out_features=2,\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "#Freeze all layers except fc\n",
    "for name, param in model.named_parameters():\n",
    "    if \"fc.weight\" in name or \"fc.bias\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classificator(L.LightningModule):\n",
    "    def __init__(self, rn50, class_labels):\n",
    "        super().__init__()\n",
    "        self.rn50 = rn50\n",
    "        self.class_labels = class_labels\n",
    "        self.train_confusion_matrix = BinaryConfusionMatrix()\n",
    "        self.val_confusion_matrix = BinaryConfusionMatrix()\n",
    "        self.test_confusion_matrix = BinaryConfusionMatrix()\n",
    "        metrics = MetricCollection([\n",
    "            BinaryPrecision(),\n",
    "            BinaryRecall(),\n",
    "            BinaryF1Score(),\n",
    "            BinaryAccuracy()\n",
    "        ])\n",
    "        self.train_metrics = metrics.clone(prefix='train_')\n",
    "        self.valid_metrics = metrics.clone(prefix='val_')\n",
    "        self.test_metrics = metrics.clone(prefix=\"test_\")\n",
    "\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        output = self.rn50(images)\n",
    "        _, preds = torch.max(output, dim=1)\n",
    "        loss = F.cross_entropy(output, labels)\n",
    "        self.log(\"Traning loss\", loss, prog_bar=True)\n",
    "        out_metric = self.train_metrics(preds, labels)\n",
    "        self.log_dict(out_metric)\n",
    "        self.train_confusion_matrix.update(preds, labels)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        cm = self.train_confusion_matrix.compute()\n",
    "        image = self.transform_confusion_matrix(cm)\n",
    "        self.logger.experiment.add_image(\"Confusion matrix train results\", image)\n",
    "        self.train_confusion_matrix.reset() \n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        output = self.rn50(images)\n",
    "        loss = F.cross_entropy(output, labels)\n",
    "        _, preds = torch.max(output, dim=1)\n",
    "        self.val_confusion_matrix.update(preds, labels)\n",
    "        self.log(\"Validation loss\", loss, prog_bar=True)\n",
    "        self.valid_metrics.update(preds, labels)\n",
    "        return loss\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        output = self.valid_metrics.compute()\n",
    "        self.log_dict(output)\n",
    "        self.valid_metrics.reset()\n",
    "        cm = self.val_confusion_matrix.compute()\n",
    "        image = self.transform_confusion_matrix(cm)\n",
    "        self.logger.experiment.add_image(\"Confusion matrix validation results\", image)\n",
    "        self.val_confusion_matrix.reset()\n",
    "    \n",
    "    def test_step(self, batch):\n",
    "        images, labels = batch\n",
    "        output = self.rn50(images)\n",
    "        loss = F.cross_entropy(output, labels)\n",
    "        _, preds = torch.max(output, dim=1)\n",
    "        self.test_metrics.update(preds, labels)\n",
    "        self.test_confusion_matrix.update(preds, labels)\n",
    "        self.log(\"Test loss\", loss, prog_bar=True)\n",
    "        self.log_dict(self.test_metrics.compute())\n",
    "\n",
    "    def on_test_end(self):\n",
    "        cm = self.test_confusion_matrix.compute()\n",
    "        image = self.transform_confusion_matrix(cm)\n",
    "        self.logger.experiment.add_image(\"Confusion matrix test results\", image)\n",
    "\n",
    "    # Takes a tensor and plot confusion matrix from it and then return as tensor\n",
    "    def transform_confusion_matrix(self, cm):\n",
    "        cm = cm.cpu().numpy()\n",
    "        fig = plt.figure()\n",
    "        sns.heatmap(cm, annot=True, xticklabels=CLASS_LABELS, yticklabels=CLASS_LABELS, fmt=\"g\", cbar=False)\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        image = PIL.Image.open(buf)\n",
    "        image = ToTensor()(image)\n",
    "        plt.close()\n",
    "        return image\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training and validation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classificator(model, CLASS_LABELS)\n",
    "early_stop_callback = EarlyStopping(monitor=\"Validation loss\", min_delta=1e-6, patience=3)\n",
    "checkpoint = L.pytorch.callbacks.ModelCheckpoint(dirpath=\"pneumonia_model/ResNet/\")\n",
    "callbacks = [early_stop_callback, checkpoint]\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "trainer.fit(\n",
    "    model = classifier,\n",
    "    train_dataloaders = train_loader, \n",
    "    val_dataloaders = val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model\n",
    "Only implemented and tested but should not use until final model is decided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.test(model = classifier, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptlightning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
